{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Modeling.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3BJHv4TqjFwf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table style=\"width:100%\">\n",
        "  <tr>\n",
        "    <td><center style=\"font-size:300%;\">Modelamento de Linguagem</center></td>\n",
        "    <td><img src=\"https://logodownload.org/wp-content/uploads/2015/02/puc-rio-logo.gif\" width=\"100\"/></td> \n",
        "  </tr>    \n",
        "</table>\n",
        "\n",
        "Msc. Cristian Mu√±oz V."
      ]
    },
    {
      "metadata": {
        "id": "lvZy5Y-iwcE_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers.core import Activation, Dense, Dropout, SpatialDropout1D\n",
        "from keras import Model, Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import LSTM , GRU, SimpleRNN\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gKcVyRF8y-YF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "rm -rf PRH.zip PRH\n",
        "wget -O PRH.zip https://github.com/fabiocorreacordeiro/wordEmbeddingsOG/raw/master/_corpus/PRH.zip\n",
        "unzip PRH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LbGfCxG3x9aj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = nltk.word_tokenize(text , language='portuguese')\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12ESfjE_wocl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath= 'PRH/20140404-MONOGRAFIA_0.txt'\n",
        "text = open(filepath,'rb').read()\n",
        "text = text.decode(\"utf-8\",\"ignore\")\n",
        "text = preprocess(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LpC-GNzIwr30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(text[:100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUops4-e0RWg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = set([word for word in text])\n",
        "vocab_size = len(words)\n",
        "w2i = {word: i for i, word in enumerate(words)}\n",
        "i2w = {v:k for k, v in w2i.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XzoQpAOP0ZPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sequence_length = 10\n",
        "step= 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gLxZBmUp0d11",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_words = [text[i:][:sequence_length] for i in range(0, len(text) - sequence_length - 1, step)]\n",
        "label_words = [text[i+1:][:sequence_length] for i in range(0, len(text) - sequence_length - 1, step)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TWPfZspk2QeT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot(targets, nb_classes):\n",
        "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
        "    return res.reshape(list(targets.shape)+[nb_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cySlQkr92HxY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = np.array([list(map(lambda w:w2i[w] , input_word)) for input_word in input_words])\n",
        "Y = np.array([list(map(lambda w:w2i[w] , label_word)) for label_word in label_words])\n",
        "Y_OH = one_hot(Y,vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JeVacmyE2QAR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 30\n",
        "epochs = 25\n",
        "emb_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YV7JmwYQ2KLv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Camda de Entrada\n",
        "input = Input(shape=[None])\n",
        "\n",
        "# Camada de Embedding\n",
        "x = Embedding(vocab_size, \n",
        "              emb_size,\n",
        "              name = \"embeddings\" , \n",
        "              embeddings_initializer=\"glorot_uniform\")(input)\n",
        "\n",
        "# Camada LSTM\n",
        "x = LSTM(hidden_size, return_sequences=True , name = \"lstm\")(x)\n",
        "\n",
        "# Camda Dropout\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Camda FC\n",
        "x = Dense(vocab_size , name = \"linear\")(x)\n",
        "output = Activation(\"softmax\" , name = \"softmax\")(x)\n",
        "\n",
        "model = Model(input=input, output=output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AcL-Bhu52mrG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UY0_uzPd2o5m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(X,Y_OH,batch_size=batch_size, epochs=epochs, verbose=1)\n",
        "model.save_weights('model.hdf5')\n",
        "print(\"loss=%f\" % (history.history[\"loss\"][-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rRrZwEZ62qOf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(history.history[\"loss\"], color=\"g\", label=\"Train\")\n",
        "plt.title('Loss')\n",
        "plt.tight_layout()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AKoZXVzq3-4a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputformat = lambda w: np.reshape(w2i[w],[1,1])\n",
        "\n",
        "def query_sentences(sentence, length, multinomial=False):\n",
        "    model.reset_states()\n",
        "    \n",
        "    words = preprocess(sentence)\n",
        "    [model.predict(inputformat(word)) for word in words[:-1]]\n",
        "        \n",
        "\n",
        "    print(words[-1] + \" \" , end=\"\")\n",
        "    startWord = inputformat(words[-1])\n",
        "    for i in range(length):         \n",
        "      \n",
        "        next_word_probs = model.predict(startWord).squeeze()\n",
        "        \n",
        "        if multinomial:\n",
        "            next_word_id = np.random.multinomial(1, next_word_probs , 1).argmax()\n",
        "        else:\n",
        "            next_word_id    = next_word_probs.squeeze().argmax()\n",
        "\n",
        "        startWord[0,0] = next_word_id \n",
        "        print(i2w[next_word_id] + \" \", end = \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_RkrALT55WYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "query_sentences(sentence='ou', length=30, multinomial=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}