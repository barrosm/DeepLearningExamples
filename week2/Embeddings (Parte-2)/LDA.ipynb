{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos a distribuição de topicos de documentos como o vetor embedding do documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessamento do Texto\n",
    "Usamos o dataset de sinopsis de filme como nossos documentos e removemos palavras raras e palavras comuns com base na sua frequência no documento. Removemos palavras que aparecem em menos de 2 documentos ou em mais de 30% dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation\n",
    "from gensim.models import ldamodel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# read data\n",
    "dataframe = pd.read_csv('movie_plots.csv')\n",
    "\n",
    "# remove stopwords and punctuations\n",
    "def preprocess(row):\n",
    "    return strip_punctuation(remove_stopwords(row.lower()))\n",
    "    \n",
    "dataframe['Plots'] = dataframe['Plots'].apply(preprocess)\n",
    "\n",
    "# Convert data to required input format by LDA\n",
    "texts = []\n",
    "for line in dataframe.Plots:\n",
    "    lowered = line.lower()\n",
    "    words = re.findall(r'\\w+', lowered, flags = re.UNICODE)# | re.LOCALE\n",
    "    texts.append(words)\n",
    "    \n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(texts)\n",
    "\n",
    "# Filter out words that occur less than 2 documents, or more than 30% of the documents.\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.3)\n",
    "\n",
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Treinamos o modelo LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 50\n",
    "iterations = 200\n",
    "eval_every = None\n",
    "\n",
    "# Train model\n",
    "model = ldamodel.LdaModel(corpus=corpus, id2word=dictionary, chunksize=chunksize, alpha='auto', \n",
    "                          eta='auto', iterations=iterations, num_topics=num_topics, passes=passes, \n",
    "                          eval_every=eval_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Distribuição de topicos de documentos\n",
    "Usamos o método get_document_topics que realiza a infrencia de a distribuição de topicos de um documento. Retorna uma lista de tupa (topic_id, probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.00042185804),\n",
       " (1, 0.00047327485),\n",
       " (2, 0.0003953588),\n",
       " (3, 0.00044829352),\n",
       " (4, 0.00044607325),\n",
       " (5, 0.00038524263),\n",
       " (6, 0.99617916),\n",
       " (7, 0.00040969712),\n",
       " (8, 0.00048974983),\n",
       " (9, 0.00035133513)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get document topics\n",
    "all_topics = model.get_document_topics(corpus, minimum_probability=0)\n",
    "all_topics[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparando os arquivos de entrada para TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorboard_helper import CreateTensorboardData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectors = [ [topics[1] for topics in doc_topics] for doc_topics in all_topics]\n",
    "metadatos = [dataframe.Titles.values , dataframe.Genres.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo com o Tensor 2D foi salvado em: doc_lda_tensor.tsv\n",
      "Arquivo com o Tensor de metadatos foi salvado em: doc_lda_metadata.tsv\n"
     ]
    }
   ],
   "source": [
    "CreateTensorboardData(tensor_filename=\"doc_lda\", \n",
    "                      vectors=vectors, \n",
    "                      metadatos=metadatos,\n",
    "                      colnames=[\"Titles\",\"Genres\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixar arquivos de vetores : <a href=\"doc_lda_tensor.tsv\" download=\"w3logo\"> doc_lda_tensor.tsv </a>\n",
    "\n",
    "Baixar arquivos com os metadatos: <a href=\"doc_lda_metadata.tsv\" download=\"w3logo\"> doc_lda_metadata.tsv </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizando usando PCA ...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levar os arquivos para http://projector.tensorflow.org/.\n",
    "\n",
    "Como podemos ver, há muitos pontos que se agrupam nos cantos. Os documentos nos cantos pertencem principalmente a um único tópico (portanto, o peso grande em uma única dimensão e outras dimensões têm peso aproximadamente zero). Você pode modificar o arquivo de metadados conforme explicado abaixo para ver os pesos das dimensões juntamente com o título do filme.\n",
    "\n",
    "Agora, vamos anexar os tópicos com maior probabilidade (topic_id, topic_probability) ao título do documento, para explorar quais tópicos os domínios ou bordas do cluster pertencem de forma dominante. Para isso, precisamos sobrescrever o arquivo de metadados conforme abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensors = []\n",
    "for doc_topics in all_topics:\n",
    "    doc_tensor = []\n",
    "    for topic in doc_topics:\n",
    "        if round(topic[1], 3) > 0:\n",
    "            doc_tensor.append((topic[0], float(round(topic[1], 3))))\n",
    "            \n",
    "    # sort topics according to highest probabilities\n",
    "    doc_tensor = sorted(doc_tensor, key=lambda x: x[1], reverse=True)\n",
    "    # store vectors to add in metadata file\n",
    "    tensors.append(doc_tensor[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo com o Tensor 2D foi salvado em: doc_lda_tensor.tsv\n",
      "Arquivo com o Tensor de metadatos foi salvado em: doc_lda_metadata.tsv\n"
     ]
    }
   ],
   "source": [
    "tensors_str = [ str(\" \".join([title, str(x)])) for title, x in zip(dataframe.Titles.values, tensors)]\n",
    "metadatos = [tensors_str, dataframe.Genres.values]\n",
    "\n",
    "CreateTensorboardData(tensor_filename=\"doc_lda\", \n",
    "                      vectors=vectors, \n",
    "                      metadatos=metadatos,\n",
    "                      colnames=[\"Titles\",\"Genres\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixar arquivos de vetores : <a href=\"doc_lda_tensor.tsv\" download=\"w3logo\"> doc_lda_tensor.tsv </a>\n",
    "\n",
    "Baixar arquivos com os metadatos: <a href=\"doc_lda_metadata.tsv\" download=\"w3logo\"> doc_lda_metadata.tsv </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizando usando T-SNE ...**\n",
    "\n",
    "Levar os arquivos para http://projector.tensorflow.org/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/Tesla/ControlCursos/DeepLearning/WordEmbedding'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.show_topic(topicid=0, topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "viz = pyLDAvis.gensim.prepare(model, corpus, dictionary)\n",
    "pyLDAvis.display(viz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
