{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Transfer Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "qYRaCPTUmhsu"
      },
      "cell_type": "markdown",
      "source": [
        "<table style=\"width:100%\" align=\"right\">\n",
        "  <tr>\n",
        "    <td><center style=\"font-size:300%;\">Transfer Learning</center></td>\n",
        "    <td><img src=\"https://logodownload.org/wp-content/uploads/2015/02/puc-rio-logo.gif\" width=\"100\"/></td> \n",
        "  </tr>    \n",
        "</table>\n",
        "\n",
        "Msc. Cristian Muñoz V."
      ]
    },
    {
      "metadata": {
        "id": "Z2wkJAV1G-sC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para baixar o dataset do repositorio:"
      ]
    },
    {
      "metadata": {
        "id": "-QFCHVN9QP25",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash \n",
        "\n",
        "file=\"/content/yalefaces\"\n",
        "if [ ! -d \"$file\" ]\n",
        "then  \n",
        "\twget https://github.com/crismunoz/DeepLearningExamples/raw/master/week1/data/yalefaces.zip\n",
        "  unzip -qq yalefaces.zip\n",
        "else\n",
        "  echo \"Dataset already exists\"\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hJseJLmwHRnB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Caso você quer testar com seu propio dataset pode subir sua pasta com o formato:\n",
        "\n",
        "-- nomedataset\n",
        "\n",
        "    -- classe1\n",
        "\n",
        "      -- img1.jpg\n",
        "\n",
        "      -- img2.jpg\n",
        "      ...\n",
        "   \n",
        "    -- classe2\n",
        "\n",
        "       -- img1.jpg\n",
        "\n",
        "       -- img2.jpg\n",
        "       ...\n",
        "       \n",
        "    ... cla..\n",
        "\n",
        "\n",
        "Em caso você tenha seu propio dataset pode subir executando a seguiente celula . Caso contrario porfavor omitir este passo."
      ]
    },
    {
      "metadata": {
        "id": "xpEc7CIPJmEn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k2_yqwgFL0xw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Baixamos arquivo utils para transfer learning:"
      ]
    },
    {
      "metadata": {
        "id": "PRsrHnTDJsWK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash \n",
        "\n",
        "file=\"/content/transfer_learning_utils.py\"\n",
        "if [ ! -d \"$file\" ]\n",
        "then  \n",
        "\twget https://github.com/crismunoz/DeepLearningExamples/raw/master/week1/transfer_learning_utils.py\n",
        "else\n",
        "  echo \"$file already exists\"\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iYf336XcMUTS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model,Input\n",
        "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.applications import  VGG16\n",
        "from keras.applications.vgg16 import preprocess_input,decode_predictions\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras import losses\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from IPython.display import Image\n",
        "from random import randint\n",
        "import matplotlib.pylab as plt\n",
        "from transfer_learning_utils import *\n",
        "\n",
        "import datetime\n",
        "now = datetime.datetime.now\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qPJVzEtwjYMa"
      },
      "cell_type": "markdown",
      "source": [
        "# Abrir Modelo Pretreinado"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mtm2bOkrlXTh"
      },
      "cell_type": "markdown",
      "source": [
        "*Modelo*:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UlmGHjdMMlhd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pretrained_model = VGG16(weights=\"imagenet\", include_top=True)\n",
        "\n",
        "for i, layer in enumerate(pretrained_model.layers):\n",
        "    print(i , layer.name, layer.output_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jiWA5JqhjeON"
      },
      "cell_type": "markdown",
      "source": [
        "Escolher a camada adecuada para realizar transfer Learning\n",
        "\n",
        "\n",
        "*Modelo Bottleneck*:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1JiCUrQ3RoBl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bottleneck_model=Model(inputs  = pretrained_model.input,\n",
        "                       outputs = pretrained_model.get_layer('flatten').output)\n",
        "bottleneck_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D8YaznWoP-ez",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset yalefaces"
      ]
    },
    {
      "metadata": {
        "id": "g1GlHbH_GZLt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://github.com/crismunoz/DeepLearningExamples/raw/master/week1/dataset/img/Alldataset.png\" width=\"600\"/></center>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Ihh4hf0mklBN"
      },
      "cell_type": "markdown",
      "source": [
        "Abrir o dataset :"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bOPBARmOSRo8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train,y_train) , (X_test,y_test) = load_data('yalefaces', 0.2)\n",
        "print('train shape:{}'.format(X_train.shape))\n",
        "print('test shape:{}'.format(X_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NVMsf1a9fJYC"
      },
      "cell_type": "markdown",
      "source": [
        "Realizamos o processo de data augmentation para os dados de treinamento e teste"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Os4NdoIFa4N3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1,\n",
        "                               shear_range=0.2, \n",
        "                               zoom_range=0.2, \n",
        "                               horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1)\n",
        "\n",
        "batch_size = 32\n",
        "train_generator = train_datagen.flow(X_train, y_train, \n",
        "                                     batch_size=batch_size, \n",
        "                                     shuffle=False)\n",
        "\n",
        "test_generator = test_datagen.flow(X_test, y_test, \n",
        "                                     batch_size=batch_size, \n",
        "                                     shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ikVWwVBudliG"
      },
      "cell_type": "markdown",
      "source": [
        "Geração de vetores de imagens (features)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "krJRbQOBW3XP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_steps_per_epoch = X_train.shape[0]//batch_size + 1\n",
        "test_steps_per_epoch = X_test.shape[0]//batch_size + 1\n",
        "\n",
        "increase_by=1\n",
        "steps_per_epoch = train_steps_per_epoch*increase_by\n",
        "train_features=[]\n",
        "train_labels=[]\n",
        "for i in range(steps_per_epoch):\n",
        "    print(\"\\rTraining Batches: {}/{}\".format(i+1,steps_per_epoch), end=\"\")\n",
        "    x,y = next(train_generator)\n",
        "    x=preprocess_input(x)\n",
        "    train_features.append(bottleneck_model.predict(x))\n",
        "    train_labels.append(y)\n",
        "\n",
        "test_features=[]\n",
        "test_labels=[]\n",
        "for i in range(test_steps_per_epoch):\n",
        "    print(\"\\rTest Batches: {}/{}\".format(i+1,test_steps_per_epoch), end=\"\")\n",
        "    x,y = next(test_generator)\n",
        "    x=preprocess_input(x)\n",
        "    test_features.append(bottleneck_model.predict(x))\n",
        "    test_labels.append(y)\n",
        "\n",
        "train_features = np.concatenate(train_features,axis=0)\n",
        "train_labels = np.concatenate(train_labels,axis=0)\n",
        "test_features = np.concatenate(test_features,axis=0)\n",
        "test_labels = np.concatenate(test_labels,axis=0)\n",
        "\n",
        "print('\\nCreation of vectors image finished!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "fjdjTuv9k1xY"
      },
      "cell_type": "markdown",
      "source": [
        "Como a extração de features é um processo demorado, se recomenda salvar  os features casso seja necessario restar o kernel."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "u6FtPG4ViMNu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = (train_features,train_labels)\n",
        "test_data = (test_features,test_labels)\n",
        "pickle.dump(train_data, open('train_features.p','wb'))\n",
        "pickle.dump(test_data, open('test_features.p','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MbjNEB4XgWFX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(train_features,train_labels) = pickle.load( open( \"train_features.p\", \"rb\" ) )\n",
        "(test_features,test_labels) = pickle.load( open( \"test_features.p\", \"rb\" ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "eqtSa0OllB8C"
      },
      "cell_type": "markdown",
      "source": [
        "Definimos nosso classificador:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fGmEz3KmSqRE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = Input(bottleneck_model.get_layer('flatten').output_shape[1:])\n",
        "x = Dense(128)(inputs)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(15)(x)\n",
        "x = Activation('softmax')(x)\n",
        "model_cls = Model(inputs=inputs, outputs=x)\n",
        "model_cls.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "P6gEDgrFlFwE"
      },
      "cell_type": "markdown",
      "source": [
        "Treinamos o modelo"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Lxvue39PX3_i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "epochs=30\n",
        "from keras import optimizers\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.001)\n",
        "\n",
        "model_cls.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "t = now()\n",
        "history=model_cls.fit(train_features, train_labels,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      verbose=1,\n",
        "                      validation_data=(test_features, test_labels))\n",
        "\n",
        "print('Training time: %s' % (now() - t))\n",
        "scorelt5 = model_cls.evaluate(test_features, test_labels, verbose=0)\n",
        "print('Test score:', scorelt5[0])\n",
        "print('Test accuracy:', scorelt5[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PCidDHp0Yik_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Improving the model's performance:\n",
        "\n",
        "Now try to improve the result you can change the hyperparameters, we encourage you to change the value of:\n",
        "\n",
        "- epochs\n",
        "- batch_size \n",
        "- increase_by\n",
        "- learning rate"
      ]
    }
  ]
}