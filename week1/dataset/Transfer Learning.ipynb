{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qYRaCPTUmhsu"
   },
   "source": [
    "<table style=\"width:100%\" align=\"right\">\n",
    "  <tr>\n",
    "    <td><center style=\"font-size:300%;\">Transfer Learning</center></td>\n",
    "    <td><img src=\"https://logodownload.org/wp-content/uploads/2015/02/puc-rio-logo.gif\" width=\"100\"/></td> \n",
    "  </tr>    \n",
    "</table>\n",
    "\n",
    "Msc. Cristian Muñoz V."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYf336XcMUTS"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model,Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.applications import  VGG16\n",
    "from keras.applications.vgg16 import preprocess_input,decode_predictions\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import losses\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import Image\n",
    "from random import randint\n",
    "import matplotlib.pylab as plt\n",
    "from transfer_learning_utils import *\n",
    "\n",
    "import datetime\n",
    "from dataset_utils import *\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qPJVzEtwjYMa"
   },
   "source": [
    "# Abrir Modelo Pretreinado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtm2bOkrlXTh"
   },
   "source": [
    "*Modelo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UlmGHjdMMlhd"
   },
   "outputs": [],
   "source": [
    "pretrained_model = VGG16(weights=\"imagenet\", include_top=True)\n",
    "\n",
    "for i, layer in enumerate(pretrained_model.layers):\n",
    "    print(i , layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jiWA5JqhjeON"
   },
   "source": [
    "Escolher a camada adecuada para realizar transfer Learning\n",
    "\n",
    "\n",
    "*Modelo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JiCUrQ3RoBl"
   },
   "outputs": [],
   "source": [
    "bottleneck_model=Model(inputs  = pretrained_model.input,\n",
    "                       outputs = pretrained_model.get_layer('flatten').output)\n",
    "bottleneck_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset yalefaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem=load_img('img/subject.jpg', target_size=(224,224,3));imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"img/Alldataset.png\", width=800, height=300)\n",
    "img_array=img_to_array(imagem).astype('float32')\n",
    "img_array=img_array.reshape((1,224,224,3))\n",
    "x=preprocess_input(img_array)\n",
    "features=bottleneck_model.predict(x)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ihh4hf0mklBN"
   },
   "source": [
    "Abrir o dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOPBARmOSRo8"
   },
   "outputs": [],
   "source": [
    "(X_train,y_train) , (X_test,y_test) = load_data('yalefaces', 0.2)\n",
    "print('train samples:{}'.format(X_train.shape[0]))\n",
    "print('test samples:{}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVMsf1a9fJYC"
   },
   "source": [
    "Realizamos o processo de data augmentation para os dados de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Os4NdoIFa4N3"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1,\n",
    "                               shear_range=0.2, \n",
    "                               zoom_range=0.2, \n",
    "                               horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1)\n",
    "\n",
    "batch_size = 32\n",
    "train_generator = train_datagen.flow(X_train, y_train, \n",
    "                                     batch_size=batch_size, \n",
    "                                     shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow(X_test, y_test, \n",
    "                                     batch_size=batch_size, \n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ikVWwVBudliG"
   },
   "source": [
    "Geração de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "krJRbQOBW3XP"
   },
   "outputs": [],
   "source": [
    "train_steps_per_epoch = X_train.shape[0]//batch_size + 1\n",
    "test_steps_per_epoch = X_test.shape[0]//batch_size + 1\n",
    "\n",
    "increase_by=1\n",
    "steps_per_epoch = train_steps_per_epoch*increase_by\n",
    "train_features=[]\n",
    "train_labels=[]\n",
    "for i in range(steps_per_epoch):\n",
    "    print(\"\\rTraining Batches: {}/{}\".format(i+1,steps_per_epoch), end=\"\")\n",
    "    x,y = next(train_generator)\n",
    "    x=preprocess_input(x)\n",
    "    train_features.append(bottleneck_model.predict(x))\n",
    "    train_labels.append(y)\n",
    "\n",
    "test_features=[]\n",
    "test_labels=[]\n",
    "for i in range(test_steps_per_epoch):\n",
    "    print(\"\\rTest Batches: {}/{}\".format(i+1,test_steps_per_epoch), end=\"\")\n",
    "    x,y = next(test_generator)\n",
    "    x=preprocess_input(x)\n",
    "    test_features.append(bottleneck_model.predict(x))\n",
    "    test_labels.append(y)\n",
    "\n",
    "train_features = np.concatenate(train_features,axis=0)\n",
    "train_labels = np.concatenate(train_labels,axis=0)\n",
    "test_features = np.concatenate(test_features,axis=0)\n",
    "test_labels = np.concatenate(test_labels,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fjdjTuv9k1xY"
   },
   "source": [
    "Como a extração de features é um processo demorado, se recomenda salvar  os features casso seja necessario restar o kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6FtPG4ViMNu"
   },
   "outputs": [],
   "source": [
    "train_data = (train_features,train_labels)\n",
    "test_data = (test_features,test_labels)\n",
    "pickle.dump(train_data, open('train_features.p','wb'))\n",
    "pickle.dump(test_data, open('test_features.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbjNEB4XgWFX"
   },
   "outputs": [],
   "source": [
    "(train_features,train_labels) = pickle.load( open( \"train_features.p\", \"rb\" ) )\n",
    "(test_features,test_labels) = pickle.load( open( \"test_features.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqtSa0OllB8C"
   },
   "source": [
    "Definimos nosso classificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGmEz3KmSqRE"
   },
   "outputs": [],
   "source": [
    "inputs = Input(bottleneck_model.get_layer('flatten').output_shape[1:])\n",
    "x = Dense(128)(inputs)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(15)(x)\n",
    "x = Activation('softmax')(x)\n",
    "model_cls = Model(inputs=inputs, outputs=x)\n",
    "model_cls.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6gEDgrFlFwE"
   },
   "source": [
    "Treinamos o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lxvue39PX3_i"
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "epochs=30\n",
    "from keras import optimizers\n",
    "# Agora, vamos treinar nosso modelo nos dígitos 0,1,2,3,4\n",
    "model_cls.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',#sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "t = now()\n",
    "history=model_cls.fit(train_features, train_labels,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      validation_data=(test_features, test_labels))\n",
    "\n",
    "print('Training time: %s' % (now() - t))\n",
    "scorelt5 = model_cls.evaluate(test_features, test_labels, verbose=0)\n",
    "print('Test score:', scorelt5[0])\n",
    "print('Test accuracy:', scorelt5[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Transfer Learning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
