{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evelyn 3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barrosm/DeepLearningExamples/blob/master/yale_faces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qYRaCPTUmhsu"
      },
      "source": [
        "<table style=\"width:100%\" align=\"right\">\n",
        "  <tr>\n",
        "    <td><center style=\"font-size:300%;\">Transfer Learning</center></td>\n",
        "    <td><img src=\"https://logodownload.org/wp-content/uploads/2015/02/puc-rio-logo.gif\" width=\"100\"/></td> \n",
        "  </tr>    \n",
        "</table>\n",
        "\n",
        "Msc. Cristian Muñoz V."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2wkJAV1G-sC",
        "colab_type": "text"
      },
      "source": [
        "Para baixar o dataset do repositorio:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QFCHVN9QP25",
        "colab_type": "code",
        "outputId": "0a93d73b-32a0-4f8f-f27c-53fe3451d13f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash \n",
        "\n",
        "rm -rf yalefaces yalefaces.zip transfer_learning_utils.py\n",
        "wget -O yalefaces.zip https://github.com/crismunoz/DeepLearningExamples/raw/master/week1/data/yalefaces.zip\n",
        "wget -O transfer_learning_utils.py https://github.com/crismunoz/DeepLearningExamples/raw/master/week1/transfer_learning_utils.py\n",
        "unzip -qq yalefaces.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-04 19:56:15--  https://github.com/crismunoz/DeepLearningExamples/raw/master/week1/data/yalefaces.zip\n",
            "Resolving github.com (github.com)... 13.229.188.59\n",
            "Connecting to github.com (github.com)|13.229.188.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/crismunoz/DeepLearningExamples/master/week1/data/yalefaces.zip [following]\n",
            "--2020-04-04 19:56:16--  https://raw.githubusercontent.com/crismunoz/DeepLearningExamples/master/week1/data/yalefaces.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6203596 (5.9M) [application/zip]\n",
            "Saving to: ‘yalefaces.zip’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 40.9M 0s\n",
            "    50K .......... .......... .......... .......... ..........  1% 33.7M 0s\n",
            "   100K .......... .......... .......... .......... ..........  2% 42.4M 0s\n",
            "   150K .......... .......... .......... .......... ..........  3% 36.0M 0s\n",
            "   200K .......... .......... .......... .......... ..........  4% 58.5M 0s\n",
            "   250K .......... .......... .......... .......... ..........  4% 44.0M 0s\n",
            "   300K .......... .......... .......... .......... ..........  5% 60.9M 0s\n",
            "   350K .......... .......... .......... .......... ..........  6% 64.6M 0s\n",
            "   400K .......... .......... .......... .......... ..........  7% 62.9M 0s\n",
            "   450K .......... .......... .......... .......... ..........  8% 51.6M 0s\n",
            "   500K .......... .......... .......... .......... ..........  9% 72.9M 0s\n",
            "   550K .......... .......... .......... .......... ..........  9% 51.5M 0s\n",
            "   600K .......... .......... .......... .......... .......... 10% 75.0M 0s\n",
            "   650K .......... .......... .......... .......... .......... 11% 80.6M 0s\n",
            "   700K .......... .......... .......... .......... .......... 12% 74.9M 0s\n",
            "   750K .......... .......... .......... .......... .......... 13%  173M 0s\n",
            "   800K .......... .......... .......... .......... .......... 14% 71.2M 0s\n",
            "   850K .......... .......... .......... .......... .......... 14% 75.1M 0s\n",
            "   900K .......... .......... .......... .......... .......... 15%  126M 0s\n",
            "   950K .......... .......... .......... .......... .......... 16% 59.3M 0s\n",
            "  1000K .......... .......... .......... .......... .......... 17%  160M 0s\n",
            "  1050K .......... .......... .......... .......... .......... 18%  119M 0s\n",
            "  1100K .......... .......... .......... .......... .......... 18% 72.4M 0s\n",
            "  1150K .......... .......... .......... .......... .......... 19%  160M 0s\n",
            "  1200K .......... .......... .......... .......... .......... 20%  106M 0s\n",
            "  1250K .......... .......... .......... .......... .......... 21%  103M 0s\n",
            "  1300K .......... .......... .......... .......... .......... 22%  115M 0s\n",
            "  1350K .......... .......... .......... .......... .......... 23%  175M 0s\n",
            "  1400K .......... .......... .......... .......... .......... 23% 91.1M 0s\n",
            "  1450K .......... .......... .......... .......... .......... 24%  152M 0s\n",
            "  1500K .......... .......... .......... .......... .......... 25%  114M 0s\n",
            "  1550K .......... .......... .......... .......... .......... 26%  183M 0s\n",
            "  1600K .......... .......... .......... .......... .......... 27%  108M 0s\n",
            "  1650K .......... .......... .......... .......... .......... 28%  247M 0s\n",
            "  1700K .......... .......... .......... .......... .......... 28%  226M 0s\n",
            "  1750K .......... .......... .......... .......... .......... 29%  103M 0s\n",
            "  1800K .......... .......... .......... .......... .......... 30%  101M 0s\n",
            "  1850K .......... .......... .......... .......... .......... 31%  205M 0s\n",
            "  1900K .......... .......... .......... .......... .......... 32%  220M 0s\n",
            "  1950K .......... .......... .......... .......... .......... 33%  173M 0s\n",
            "  2000K .......... .......... .......... .......... .......... 33%  217M 0s\n",
            "  2050K .......... .......... .......... .......... .......... 34%  107M 0s\n",
            "  2100K .......... .......... .......... .......... .......... 35%  212M 0s\n",
            "  2150K .......... .......... .......... .......... .......... 36%  183M 0s\n",
            "  2200K .......... .......... .......... .......... .......... 37%  184M 0s\n",
            "  2250K .......... .......... .......... .......... .......... 37%  204M 0s\n",
            "  2300K .......... .......... .......... .......... .......... 38%  124M 0s\n",
            "  2350K .......... .......... .......... .......... .......... 39%  241M 0s\n",
            "  2400K .......... .......... .......... .......... .......... 40%  208M 0s\n",
            "  2450K .......... .......... .......... .......... .......... 41%  139M 0s\n",
            "  2500K .......... .......... .......... .......... .......... 42%  243M 0s\n",
            "  2550K .......... .......... .......... .......... .......... 42%  199M 0s\n",
            "  2600K .......... .......... .......... .......... .......... 43%  178M 0s\n",
            "  2650K .......... .......... .......... .......... .......... 44%  217M 0s\n",
            "  2700K .......... .......... .......... .......... .......... 45%  138M 0s\n",
            "  2750K .......... .......... .......... .......... .......... 46%  196M 0s\n",
            "  2800K .......... .......... .......... .......... .......... 47%  183M 0s\n",
            "  2850K .......... .......... .......... .......... .......... 47%  237M 0s\n",
            "  2900K .......... .......... .......... .......... .......... 48%  219M 0s\n",
            "  2950K .......... .......... .......... .......... .......... 49%  188M 0s\n",
            "  3000K .......... .......... .......... .......... .......... 50%  189M 0s\n",
            "  3050K .......... .......... .......... .......... .......... 51%  226M 0s\n",
            "  3100K .......... .......... .......... .......... .......... 51%  268M 0s\n",
            "  3150K .......... .......... .......... .......... .......... 52%  135M 0s\n",
            "  3200K .......... .......... .......... .......... .......... 53%  213M 0s\n",
            "  3250K .......... .......... .......... .......... .......... 54%  275M 0s\n",
            "  3300K .......... .......... .......... .......... .......... 55%  259M 0s\n",
            "  3350K .......... .......... .......... .......... .......... 56%  150M 0s\n",
            "  3400K .......... .......... .......... .......... .......... 56%  229M 0s\n",
            "  3450K .......... .......... .......... .......... .......... 57%  268M 0s\n",
            "  3500K .......... .......... .......... .......... .......... 58%  225M 0s\n",
            "  3550K .......... .......... .......... .......... .......... 59%  206M 0s\n",
            "  3600K .......... .......... .......... .......... .......... 60%  220M 0s\n",
            "  3650K .......... .......... .......... .......... .......... 61%  244M 0s\n",
            "  3700K .......... .......... .......... .......... .......... 61%  231M 0s\n",
            "  3750K .......... .......... .......... .......... .......... 62%  222M 0s\n",
            "  3800K .......... .......... .......... .......... .......... 63%  213M 0s\n",
            "  3850K .......... .......... .......... .......... .......... 64%  222M 0s\n",
            "  3900K .......... .......... .......... .......... .......... 65%  260M 0s\n",
            "  3950K .......... .......... .......... .......... .......... 66%  199M 0s\n",
            "  4000K .......... .......... .......... .......... .......... 66%  215M 0s\n",
            "  4050K .......... .......... .......... .......... .......... 67%  265M 0s\n",
            "  4100K .......... .......... .......... .......... .......... 68%  227M 0s\n",
            "  4150K .......... .......... .......... .......... .......... 69%  182M 0s\n",
            "  4200K .......... .......... .......... .......... .......... 70%  283M 0s\n",
            "  4250K .......... .......... .......... .......... .......... 70%  196M 0s\n",
            "  4300K .......... .......... .......... .......... .......... 71%  206M 0s\n",
            "  4350K .......... .......... .......... .......... .......... 72%  223M 0s\n",
            "  4400K .......... .......... .......... .......... .......... 73%  222M 0s\n",
            "  4450K .......... .......... .......... .......... .......... 74%  182M 0s\n",
            "  4500K .......... .......... .......... .......... .......... 75%  213M 0s\n",
            "  4550K .......... .......... .......... .......... .......... 75%  192M 0s\n",
            "  4600K .......... .......... .......... .......... .......... 76%  237M 0s\n",
            "  4650K .......... .......... .......... .......... .......... 77%  137M 0s\n",
            "  4700K .......... .......... .......... .......... .......... 78%  232M 0s\n",
            "  4750K .......... .......... .......... .......... .......... 79%  244M 0s\n",
            "  4800K .......... .......... .......... .......... .......... 80%  281M 0s\n",
            "  4850K .......... .......... .......... .......... .......... 80%  291M 0s\n",
            "  4900K .......... .......... .......... .......... .......... 81%  192M 0s\n",
            "  4950K .......... .......... .......... .......... .......... 82%  204M 0s\n",
            "  5000K .......... .......... .......... .......... .......... 83%  272M 0s\n",
            "  5050K .......... .......... .......... .......... .......... 84%  241M 0s\n",
            "  5100K .......... .......... .......... .......... .......... 85%  190M 0s\n",
            "  5150K .......... .......... .......... .......... .......... 85%  239M 0s\n",
            "  5200K .......... .......... .......... .......... .......... 86%  247M 0s\n",
            "  5250K .......... .......... .......... .......... .......... 87%  201M 0s\n",
            "  5300K .......... .......... .......... .......... .......... 88%  200M 0s\n",
            "  5350K .......... .......... .......... .......... .......... 89%  224M 0s\n",
            "  5400K .......... .......... .......... .......... .......... 89%  225M 0s\n",
            "  5450K .......... .......... .......... .......... .......... 90%  181M 0s\n",
            "  5500K .......... .......... .......... .......... .......... 91%  247M 0s\n",
            "  5550K .......... .......... .......... .......... .......... 92%  218M 0s\n",
            "  5600K .......... .......... .......... .......... .......... 93%  232M 0s\n",
            "  5650K .......... .......... .......... .......... .......... 94%  241M 0s\n",
            "  5700K .......... .......... .......... .......... .......... 94%  227M 0s\n",
            "  5750K .......... .......... .......... .......... .......... 95%  245M 0s\n",
            "  5800K .......... .......... .......... .......... .......... 96%  291M 0s\n",
            "  5850K .......... .......... .......... .......... .......... 97%  275M 0s\n",
            "  5900K .......... .......... .......... .......... .......... 98%  241M 0s\n",
            "  5950K .......... .......... .......... .......... .......... 99%  220M 0s\n",
            "  6000K .......... .......... .......... .......... .......... 99%  278M 0s\n",
            "  6050K ........                                              100%  227M=0.04s\n",
            "\n",
            "2020-04-04 19:56:18 (137 MB/s) - ‘yalefaces.zip’ saved [6203596/6203596]\n",
            "\n",
            "--2020-04-04 19:56:18--  https://github.com/crismunoz/DeepLearningExamples/raw/master/week1/transfer_learning_utils.py\n",
            "Resolving github.com (github.com)... 13.229.188.59\n",
            "Connecting to github.com (github.com)|13.229.188.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/crismunoz/DeepLearningExamples/master/week1/transfer_learning_utils.py [following]\n",
            "--2020-04-04 19:56:18--  https://raw.githubusercontent.com/crismunoz/DeepLearningExamples/master/week1/transfer_learning_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3668 (3.6K) [text/plain]\n",
            "Saving to: ‘transfer_learning_utils.py’\n",
            "\n",
            "     0K ...                                                   100% 36.9M=0s\n",
            "\n",
            "2020-04-04 19:56:19 (36.9 MB/s) - ‘transfer_learning_utils.py’ saved [3668/3668]\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJseJLmwHRnB",
        "colab_type": "text"
      },
      "source": [
        "A estrutura de pastas do dataset é a seguiente:\n",
        "\n",
        "-- nomedataset\n",
        "\n",
        "    -- *classe1*\n",
        "\n",
        "      -- img1.jpg\n",
        "\n",
        "      -- img2.jpg\n",
        "      ...\n",
        "   \n",
        "    -- *classe2*\n",
        "\n",
        "       -- img1.jpg\n",
        "\n",
        "       -- img2.jpg\n",
        "       ...\n",
        "       \n",
        "    ... *cla..*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed-gmBAkxHxv",
        "colab_type": "text"
      },
      "source": [
        "## Aqui vamos trabalhar com data augmentation e redes pré-treinadas\n",
        "### Base de dados é Yale Face database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iYf336XcMUTS",
        "outputId": "19aaed9f-0e8b-4fd5-d0f3-87565770823c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "from keras.models import Model,Input\n",
        "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.applications import  VGG16\n",
        "from keras.applications.vgg16 import preprocess_input,decode_predictions\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras import losses\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from IPython.display import Image\n",
        "from random import randint\n",
        "import matplotlib.pylab as plt\n",
        "from transfer_learning_utils import *\n",
        "\n",
        "import datetime\n",
        "now = datetime.datetime.now\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qPJVzEtwjYMa"
      },
      "source": [
        "# Abrir Modelo Pretreinado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mtm2bOkrlXTh"
      },
      "source": [
        "*Modelo*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UlmGHjdMMlhd",
        "outputId": "364fc888-a996-486d-a47f-9d168e7ee8f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "source": [
        "pretrained_model = VGG16(weights=\"imagenet\", include_top=True)\n",
        "\n",
        "for i, layer in enumerate(pretrained_model.layers):\n",
        "    print(i , layer.name, layer.output_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 40s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "0 input_1 (None, 224, 224, 3)\n",
            "1 block1_conv1 (None, 224, 224, 64)\n",
            "2 block1_conv2 (None, 224, 224, 64)\n",
            "3 block1_pool (None, 112, 112, 64)\n",
            "4 block2_conv1 (None, 112, 112, 128)\n",
            "5 block2_conv2 (None, 112, 112, 128)\n",
            "6 block2_pool (None, 56, 56, 128)\n",
            "7 block3_conv1 (None, 56, 56, 256)\n",
            "8 block3_conv2 (None, 56, 56, 256)\n",
            "9 block3_conv3 (None, 56, 56, 256)\n",
            "10 block3_pool (None, 28, 28, 256)\n",
            "11 block4_conv1 (None, 28, 28, 512)\n",
            "12 block4_conv2 (None, 28, 28, 512)\n",
            "13 block4_conv3 (None, 28, 28, 512)\n",
            "14 block4_pool (None, 14, 14, 512)\n",
            "15 block5_conv1 (None, 14, 14, 512)\n",
            "16 block5_conv2 (None, 14, 14, 512)\n",
            "17 block5_conv3 (None, 14, 14, 512)\n",
            "18 block5_pool (None, 7, 7, 512)\n",
            "19 flatten (None, 25088)\n",
            "20 fc1 (None, 4096)\n",
            "21 fc2 (None, 4096)\n",
            "22 predictions (None, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jiWA5JqhjeON"
      },
      "source": [
        "Escolher a camada adecuada para realizar transfer Learning\n",
        "\n",
        "\n",
        "*Modelo Bottleneck*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1JiCUrQ3RoBl",
        "outputId": "95340dc6-cb19-4133-d21f-cc0a8d396617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        }
      },
      "source": [
        "bottleneck_model=Model(inputs  = pretrained_model.input,\n",
        "                       outputs = pretrained_model.get_layer('flatten').output)\n",
        "bottleneck_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8YaznWoP-ez",
        "colab_type": "text"
      },
      "source": [
        "# Dataset yalefaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1GlHbH_GZLt",
        "colab_type": "text"
      },
      "source": [
        "<center><img src=\"https://github.com/crismunoz/DeepLearningExamples/raw/master/week1/dataset/img/Alldataset.png\" width=\"600\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ihh4hf0mklBN"
      },
      "source": [
        "Abrir o dataset :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bOPBARmOSRo8",
        "outputId": "a65b699e-3123-4ba0-8470-1160e69be081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "(X_train,y_train) , (X_test,y_test) = load_data('yalefaces', 0.2)\n",
        "print('train shape:{}'.format(X_train.shape))\n",
        "print('test shape:{}'.format(X_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 166 images belonging to 15 classes.\n",
            "train shape:(132, 224, 224, 3)\n",
            "test shape:(34, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NVMsf1a9fJYC"
      },
      "source": [
        "Realizamos o processo de data augmentation para os dados de treinamento e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Os4NdoIFa4N3",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1,\n",
        "                               shear_range=0.2, \n",
        "                               zoom_range=0.2, \n",
        "                               horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1)\n",
        "\n",
        "batch_size = 32\n",
        "train_generator = train_datagen.flow(X_train, y_train, \n",
        "                                     batch_size=batch_size, \n",
        "                                     shuffle=False)\n",
        "\n",
        "test_generator = test_datagen.flow(X_test, y_test, \n",
        "                                     batch_size=batch_size, \n",
        "                                     shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ikVWwVBudliG"
      },
      "source": [
        "Geração de vetores de imagens (features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "krJRbQOBW3XP",
        "outputId": "803f0735-f655-47c2-c144-47383c47373e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_steps_per_epoch = X_train.shape[0]//batch_size + 1\n",
        "test_steps_per_epoch = X_test.shape[0]//batch_size + 1\n",
        "\n",
        "increase_by=1\n",
        "steps_per_epoch = train_steps_per_epoch*increase_by\n",
        "train_features=[]\n",
        "train_labels=[]\n",
        "for i in range(steps_per_epoch):\n",
        "    print(\"\\rTraining Batches: {}/{}\".format(i+1,steps_per_epoch), end=\"\")\n",
        "    x,y = next(train_generator)\n",
        "    x=preprocess_input(x)\n",
        "    train_features.append(bottleneck_model.predict(x))\n",
        "    train_labels.append(y)\n",
        "\n",
        "test_features=[]\n",
        "test_labels=[]\n",
        "for i in range(test_steps_per_epoch):\n",
        "    print(\"\\rTest Batches: {}/{}\".format(i+1,test_steps_per_epoch), end=\"\")\n",
        "    x,y = next(test_generator)\n",
        "    x=preprocess_input(x)\n",
        "    test_features.append(bottleneck_model.predict(x))\n",
        "    test_labels.append(y)\n",
        "\n",
        "train_features = np.concatenate(train_features,axis=0)\n",
        "train_labels = np.concatenate(train_labels,axis=0)\n",
        "test_features = np.concatenate(test_features,axis=0)\n",
        "test_labels = np.concatenate(test_labels,axis=0)\n",
        "\n",
        "print('\\nCreation of vectors image finished!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Batches: 2/2\n",
            "Creation of vectors image finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fjdjTuv9k1xY"
      },
      "source": [
        "Como a extração de features é um processo demorado, se recomenda salvar  os features casso seja necessario restar o kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u6FtPG4ViMNu",
        "colab": {}
      },
      "source": [
        "train_data = (train_features,train_labels)\n",
        "test_data = (test_features,test_labels)\n",
        "pickle.dump(train_data, open('train_features.p','wb'))\n",
        "pickle.dump(test_data, open('test_features.p','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MbjNEB4XgWFX",
        "colab": {}
      },
      "source": [
        "(train_features,train_labels) = pickle.load( open( \"train_features.p\", \"rb\" ) )\n",
        "(test_features,test_labels) = pickle.load( open( \"test_features.p\", \"rb\" ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eqtSa0OllB8C"
      },
      "source": [
        "Definimos nosso classificador:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fGmEz3KmSqRE",
        "outputId": "1d0dc73f-c928-4878-b01e-1c65a8106298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "inputs = Input(bottleneck_model.get_layer('flatten').output_shape[1:])\n",
        "x = Dense(128)(inputs)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(15)(x)\n",
        "x = Activation('softmax')(x)\n",
        "model_cls = Model(inputs=inputs, outputs=x)\n",
        "model_cls.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15)                1935      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 3,213,327\n",
            "Trainable params: 3,213,327\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P6gEDgrFlFwE"
      },
      "source": [
        "Treinamos o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lxvue39PX3_i",
        "outputId": "440d1a5c-7008-4719-f727-342ee5bba262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size=32\n",
        "epochs=30\n",
        "from keras import optimizers\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.001)\n",
        "\n",
        "model_cls.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "t = now()\n",
        "history=model_cls.fit(train_features, train_labels,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      verbose=1,\n",
        "                      validation_data=(test_features, test_labels))\n",
        "\n",
        "print('Training time: %s' % (now() - t))\n",
        "scorelt5 = model_cls.evaluate(test_features, test_labels, verbose=0)\n",
        "print('Test score:', scorelt5[0])\n",
        "print('Test accuracy:', scorelt5[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 132 samples, validate on 34 samples\n",
            "Epoch 1/30\n",
            "132/132 [==============================] - 0s 4ms/step - loss: 12.8280 - acc: 0.1364 - val_loss: 10.8535 - val_acc: 0.2353\n",
            "Epoch 2/30\n",
            "132/132 [==============================] - 0s 364us/step - loss: 11.6985 - acc: 0.2197 - val_loss: 10.0235 - val_acc: 0.3529\n",
            "Epoch 3/30\n",
            "132/132 [==============================] - 0s 287us/step - loss: 11.3840 - acc: 0.2727 - val_loss: 10.6359 - val_acc: 0.3235\n",
            "Epoch 4/30\n",
            "132/132 [==============================] - 0s 277us/step - loss: 11.0723 - acc: 0.2803 - val_loss: 11.1699 - val_acc: 0.2941\n",
            "Epoch 5/30\n",
            "132/132 [==============================] - 0s 308us/step - loss: 10.6836 - acc: 0.3182 - val_loss: 10.3256 - val_acc: 0.3529\n",
            "Epoch 6/30\n",
            "132/132 [==============================] - 0s 268us/step - loss: 9.5167 - acc: 0.4015 - val_loss: 9.9163 - val_acc: 0.3824\n",
            "Epoch 7/30\n",
            "132/132 [==============================] - 0s 263us/step - loss: 9.1020 - acc: 0.4091 - val_loss: 9.9244 - val_acc: 0.3824\n",
            "Epoch 8/30\n",
            "132/132 [==============================] - 0s 267us/step - loss: 10.2595 - acc: 0.3409 - val_loss: 9.9553 - val_acc: 0.3824\n",
            "Epoch 9/30\n",
            "132/132 [==============================] - 0s 273us/step - loss: 10.2591 - acc: 0.3409 - val_loss: 10.8176 - val_acc: 0.3235\n",
            "Epoch 10/30\n",
            "132/132 [==============================] - 0s 281us/step - loss: 9.4497 - acc: 0.3864 - val_loss: 10.7995 - val_acc: 0.3235\n",
            "Epoch 11/30\n",
            "132/132 [==============================] - 0s 272us/step - loss: 8.7408 - acc: 0.4394 - val_loss: 8.7501 - val_acc: 0.4412\n",
            "Epoch 12/30\n",
            "132/132 [==============================] - 0s 275us/step - loss: 8.5435 - acc: 0.4242 - val_loss: 8.5331 - val_acc: 0.4706\n",
            "Epoch 13/30\n",
            "132/132 [==============================] - 0s 286us/step - loss: 8.4321 - acc: 0.4621 - val_loss: 8.7063 - val_acc: 0.4412\n",
            "Epoch 14/30\n",
            "132/132 [==============================] - 0s 259us/step - loss: 7.6494 - acc: 0.5076 - val_loss: 9.0072 - val_acc: 0.4412\n",
            "Epoch 15/30\n",
            "132/132 [==============================] - 0s 270us/step - loss: 7.4403 - acc: 0.5152 - val_loss: 9.2869 - val_acc: 0.4118\n",
            "Epoch 16/30\n",
            "132/132 [==============================] - 0s 283us/step - loss: 7.4771 - acc: 0.5227 - val_loss: 9.0073 - val_acc: 0.4412\n",
            "Epoch 17/30\n",
            "132/132 [==============================] - 0s 268us/step - loss: 7.0512 - acc: 0.5530 - val_loss: 8.5600 - val_acc: 0.4412\n",
            "Epoch 18/30\n",
            "132/132 [==============================] - 0s 295us/step - loss: 6.9517 - acc: 0.5455 - val_loss: 8.5331 - val_acc: 0.4706\n",
            "Epoch 19/30\n",
            "132/132 [==============================] - 0s 267us/step - loss: 6.3940 - acc: 0.5909 - val_loss: 8.0888 - val_acc: 0.4706\n",
            "Epoch 20/30\n",
            "132/132 [==============================] - 0s 286us/step - loss: 6.5349 - acc: 0.5530 - val_loss: 7.2942 - val_acc: 0.5000\n",
            "Epoch 21/30\n",
            "132/132 [==============================] - 0s 276us/step - loss: 5.9579 - acc: 0.5985 - val_loss: 6.6369 - val_acc: 0.5882\n",
            "Epoch 22/30\n",
            "132/132 [==============================] - 0s 357us/step - loss: 4.9531 - acc: 0.6742 - val_loss: 6.6369 - val_acc: 0.5882\n",
            "Epoch 23/30\n",
            "132/132 [==============================] - 0s 422us/step - loss: 4.7251 - acc: 0.7045 - val_loss: 6.6369 - val_acc: 0.5882\n",
            "Epoch 24/30\n",
            "132/132 [==============================] - 0s 284us/step - loss: 4.9703 - acc: 0.6742 - val_loss: 6.6369 - val_acc: 0.5882\n",
            "Epoch 25/30\n",
            "132/132 [==============================] - 0s 278us/step - loss: 4.8703 - acc: 0.6970 - val_loss: 6.6369 - val_acc: 0.5882\n",
            "Epoch 26/30\n",
            "132/132 [==============================] - 0s 311us/step - loss: 4.0940 - acc: 0.7424 - val_loss: 6.6375 - val_acc: 0.5882\n",
            "Epoch 27/30\n",
            "132/132 [==============================] - 0s 280us/step - loss: 5.0088 - acc: 0.6591 - val_loss: 6.6243 - val_acc: 0.5882\n",
            "Epoch 28/30\n",
            "132/132 [==============================] - 0s 267us/step - loss: 4.3603 - acc: 0.7045 - val_loss: 5.3627 - val_acc: 0.6471\n",
            "Epoch 29/30\n",
            "132/132 [==============================] - 0s 286us/step - loss: 3.8430 - acc: 0.7348 - val_loss: 4.9033 - val_acc: 0.6765\n",
            "Epoch 30/30\n",
            "132/132 [==============================] - 0s 281us/step - loss: 3.8752 - acc: 0.7424 - val_loss: 5.2929 - val_acc: 0.6471\n",
            "Training time: 0:00:01.873955\n",
            "Test score: 5.292897848521963\n",
            "Test accuracy: 0.6470588235294118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCidDHp0Yik_",
        "colab_type": "text"
      },
      "source": [
        "# Improving the model's performance:\n",
        "\n",
        "Now try to improve the result you can change the hyperparameters, we encourage you to change the value of:\n",
        "\n",
        "- epochs\n",
        "- batch_size \n",
        "- increase_by\n",
        "- learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff_Ho8DxDJpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}